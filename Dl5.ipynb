{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfkSfDDQjZzaEPQR3SmJDx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibad17/assignment/blob/main/Dl5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "2SeJ-28CnVET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow  # Only for Colab\n",
        "\n",
        "# Load the pretrained model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# COCO category names\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle',\n",
        "    'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',\n",
        "    'bird', 'cat', 'dog', 'lamb', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
        "    'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
        "    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "def detect_objects(image_path, output_path=None, confidence_threshold=0.5, device='cpu'):\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not load image from '{image_path}'. Please check the file path and ensure the image exists.\")\n",
        "        return None\n",
        "\n",
        "    # Resize image if too large\n",
        "    max_size = 40\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        image = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
        "\n",
        "    # Prepare image tensor\n",
        "    image_tensor = F.to_tensor(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    labels = predictions[0]['labels'].cpu().numpy()\n",
        "    scores = predictions[0]['scores'].cpu().numpy()\n",
        "\n",
        "    # Draw bounding boxes for high-confidence detections\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] >= confidence_threshold:\n",
        "            label = COCO_INSTANCE_CATEGORY_NAMES[labels[i]]\n",
        "            score = scores[i]\n",
        "            start_point = (int(box[0]), int(box[1]))\n",
        "            end_point = (int(box[2]), int(box[3]))\n",
        "            cv2.rectangle(image, start_point, end_point, (0, 255, 0), 2)\n",
        "            cv2.putText(image, f\"{label}: {score:.2f}\", start_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Save or display the image\n",
        "    if output_path:\n",
        "        cv2.imwrite(output_path, image)\n",
        "        print(f\"Output saved to {output_path}\")\n",
        "    else:\n",
        "        # Use cv2.imshow in local environments or cv2_imshow in Colab\n",
        "        try:\n",
        "            cv2_imshow(image)  # For Colab\n",
        "        except ImportError:\n",
        "            cv2.imshow(\"Detected Objects\", image)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "    return image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Handle argparse in a Jupyter/Colab safe way\n",
        "    try:\n",
        "        parser = argparse.ArgumentParser(description=\"Object Detection with Faster R-CNN\")\n",
        "        parser.add_argument(\"image_path\", type=str, help=\"Path to the input image.\")\n",
        "        parser.add_argument(\"--output_path\", type=str, default=None, help=\"Path to save the output image.\")\n",
        "        parser.add_argument(\"--confidence\", type=float, default=0.5, help=\"Confidence threshold for object detection.\")\n",
        "        parser.add_argument(\"--use_gpu\", action=\"store_true\", help=\"Use GPU for inference if available.\")\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        device = \"cuda\" if args.use_gpu and torch.cuda.is_available() else \"cpu\"\n",
        "        detect_objects(args.image_path, args.output_path, args.confidence, device)\n",
        "    except SystemExit:\n",
        "        # Use fallback testing for Jupyter/Colab\n",
        "        print(\"Argparse not supported. Running fallback.\")\n",
        "        IMAGE_PATH = \"/dog.jpeg\"  # Replace with your test image path\n",
        "        OUTPUT_PATH = None  # Set to \"output.jpg\" if you want to save\n",
        "        CONFIDENCE_THRESHOLD = 0.5\n",
        "        USE_GPU = True\n",
        "\n",
        "        device = \"cuda\" if USE_GPU and torch.cuda.is_available() else \"cpu\"\n",
        "        detect_objects(IMAGE_PATH, OUTPUT_PATH, CONFIDENCE_THRESHOLD, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RvK_m-LoThX",
        "outputId": "4f019130-7765-4ab5-85a7-5db29ab95ea0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:01<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argparse not supported. Running fallback.\n",
            "Error: Could not load image from '/dog.jpeg'. Please check the file path and ensure the image exists.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--output_path OUTPUT_PATH] [--confidence CONFIDENCE]\n",
            "                                [--use_gpu]\n",
            "                                image_path\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow  # For Colab\n",
        "\n",
        "# Load the pretrained model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# COCO category names\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle',\n",
        "    'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',\n",
        "    'bird', 'cat', 'dog', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
        "    'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
        "    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "def detect_objects(image_path, output_path=None, confidence_threshold=0.5, device='cpu'):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not load image from '{image_path}'. Please check the file path and ensure the image exists.\")\n",
        "        return None\n",
        "\n",
        "    # Resize the image if too large\n",
        "    max_size = 40 # Keep this realistic\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        image = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
        "\n",
        "    # Prepare the image tensor\n",
        "    image_tensor = F.to_tensor(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    labels = predictions[0]['labels'].cpu().numpy()\n",
        "    scores = predictions[0]['scores'].cpu().numpy()\n",
        "\n",
        "    # Draw bounding boxes for high-confidence detections\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] >= confidence_threshold:\n",
        "            label = COCO_INSTANCE_CATEGORY_NAMES[labels[i]]\n",
        "            score = scores[i]\n",
        "            start_point = (int(box[0]), int(box[1]))\n",
        "            end_point = (int(box[2]), int(box[3]))\n",
        "            cv2.rectangle(image, start_point, end_point, (0, 255, 0), 2)\n",
        "            cv2.putText(image, f\"{label}: {score:.2f}\", (start_point[0], start_point[1] - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Save or display the image\n",
        "    if output_path:\n",
        "        cv2.imwrite(output_path, image)\n",
        "        print(f\"Output saved to {output_path}\")\n",
        "    else:\n",
        "        # Use cv2.imshow for local environments or cv2_imshow for Colab\n",
        "        try:\n",
        "            cv2_imshow(image)  # For Colab\n",
        "        except ImportError:\n",
        "            cv2.imshow(\"Detected Objects\", image)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "    return image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        parser = argparse.ArgumentParser(description=\"Object Detection with Faster R-CNN\")\n",
        "        parser.add_argument(\"image_path\", type=str, help=\"Path to the input image.\")\n",
        "        parser.add_argument(\"--output_path\", type=str, default=None, help=\"Path to save the output image.\")\n",
        "        parser.add_argument(\"--confidence\", type=float, default=0.5, help=\"Confidence threshold for object detection.\")\n",
        "        parser.add_argument(\"--use_gpu\", action=\"store_true\", help=\"Use GPU for inference if available.\")\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        device = \"cuda\" if args.use_gpu and torch.cuda.is_available() else \"cpu\"\n",
        "        detect_objects(args.image_path, args.output_path, args.confidence, device)\n",
        "    except SystemExit:\n",
        "        # Handle Jupyter/Colab fallback\n",
        "        print(\"Argparse not supported in this environment. Running fallback.\")\n",
        "        IMAGE_PATH = \"traffic.jpeg\"  # Replace with your test image path\n",
        "        OUTPUT_PATH = None  # Set to \"output.jpg\" if you want to save the result\n",
        "        CONFIDENCE_THRESHOLD = 0.5\n",
        "        USE_GPU = True\n",
        "\n",
        "        device = \"cuda\" if USE_GPU and torch.cuda.is_available() else \"cpu\"\n",
        "        detect_objects(IMAGE_PATH, OUTPUT_PATH, CONFIDENCE_THRESHOLD, device)\n"
      ],
      "metadata": {
        "id": "XFwVEiU_o5W8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "6e6774c1-ccf8-4e77-d289-e04234d0954d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--output_path OUTPUT_PATH] [--confidence CONFIDENCE]\n",
            "                                [--use_gpu]\n",
            "                                image_path\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argparse not supported in this environment. Running fallback.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=37x40>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAoACUDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1vxb4mPhnTvPNs8jyq4ikxmNHC5UPyDzzwOymvL5vi94o+w/aU0/SGiCmUkl8lcZDAbunBPXOOwPFel+OotHu/Dd1Y6vd2UEksbvZ/aZNhEqrwy4+YkEjO0HIOMHOD8tGa6+wGQ27iDGGYr8uSfp0xxis6jkrcp1YVYd83t29tLdz6f8ADvjH+3/DtzepblLi0tlkkJXEbSFCSF5JxkdCc4Irj5PiFqA1VNLa9Y3D9FMCY+6W9OmBXTeFodHsvhzJYaVd2VxJDY7ro20u8mVo/mZs/MMkHGQMAYwMYHl8n2I+KYWTT5FvBOUe78zKOvkE7dueDyOgzx1wa8nM5T9paMmrRk9HbVdz5rMW3VmuZq1OclaTXvJq22/oe/WE73WnW1w4UNLErsF6ZIBoqPR/+QJYf9e0f/oIor1qTbpxb7I9ag3KlFvsjmviVoz6p4RuLiF1S4sVa4BI+8gHzrwDjI5+oHTqPGE8T2n/AAgb6V5LpceSYg+ATnbnPrn3x17969n+JUurW3heW405pGgCvHeQpEr7omXBY5BIA747MScAZrwtjZP4aM0c91HdiPAJuif3mDgEkgY98D14rnxkKUlD2l91a3c0eLWG3+1oez/Djw5La+AQ91MhudWt1k3RgkRxMnyLg4yQGJPA5bHIANZo8E3E2uSWxeD7Tbxx3O4yvtw+9BgY64Ru3cVs/C661e98LRXGoFhaiOOKzjaMKQirgsMAZB4AJz90+tb1vn/hNdQBx/yDrXt/00uKMTgaWJac76aaOxw4vLqOLkpVL3Sto7aM07O2+y2Vvbl93kxrHuxjOBjNFTY5zk/SiuuMVFJI7YxUUorZHBXHxN8GX+nTQz3bPbXKmGRD8pIYYIxncBg9eK89KfCVYxB9u1ry1UoEUvtxnJHTkZ5//UKKK05UFzurL4seB9OsYLO1uLlLeCNYok8hztVQABk89AKqj4m+DV1KS/GsakJpAiOPsw2lFZmVMbOnztz1560UU+VBc1JPjB4PjbDXk57fLCW/lRRRRyoLs//Z\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}