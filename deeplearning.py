# -*- coding: utf-8 -*-
"""DeepLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RObIo596NmfShCOU9i0TuLLNo9C3I-ZX
"""

import tensorflow as tf
from tensorflow import keras
fashion_mnsit=keras.datasets.fashion_mnist
(X_train_full,y_train_full),(X_test,y_test)=fashion_mnsit.load_data()

X_valid,X_train=X_train_full[:5000]/255.0,X_train_full[5000:]/255.0
y_valid,y_train=y_train_full[:5000],y_train_full[5000:]
class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']

X_valid.shape

model=keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=[28,28]))
model.add(keras.layers.Dense(500,activation='relu'))
model.add(keras.layers.Dense(350,activation='relu'))
model.add(keras.layers.Dense(100,activation='relu'))
model.add(keras.layers.Dense(10,activation='softmax'))
model.summary()
hidden1=model.layers[1]
weights,biases=hidden1.get_weights()

model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])

history=model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))

import pandas as pd
import matplotlib.pyplot as plt
pd.DataFrame(history.history).plot(figsize=(8,5))
plt.grid(True)
plt.gca().set_ylim(0,1)
plt.show()
model.evaluate(X_test,y_test)

X_new=X_test[:5]
y_proba=model.predict(X_new)
y_proba.round(2)
y_proba

import numpy as np
y_pred=model.predict(X_new)
y_pred_classes=np.argmax(y_pred,axis=-1)
y_pred_classes

predicted_classes=[class_names[i] for i in y_pred_classes]
predicted_classes

predicted_classes=np.array(class_names)[y_pred_classes]
predicted_classes

from sklearn.metrics import accuracy_score
accuracy_score(y_test[:5],y_pred_classes)

#BUILDING AN REGRESSION USING THE SEQUENTIAL API
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
housing=fetch_california_housing()
X_train_full,X_test,y_train_full,y_test=train_test_split(housing.data,housing.target)
X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full)
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_valid=scaler.transform(X_valid)
X_test=scaler.transform(X_test)

X_valid.shape

housing.DESCR

housing_df=pd.DataFrame(housing.data,columns=housing.feature_names)
housing_df.head()

input=keras.layers.Input(shape=X_train.shape[1:])
hidden1=keras.layers.Dense(30,activation='relu')(input)
hidden2=keras.layers.Dense(30,activation='relu')(hidden1)
concat=keras.layers.Concatenate()([input,hidden2])
output=keras.layers.Dense(1)(concat)
model=keras.models.Model(inputs=[input],outputs=[output])

model.compile(loss='mean_absolute_error',optimizer='sgd')
history=model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))
mse_test=model.evaluate(X_test,y_test)
X_new=X_test[:3]
y_pred=model.predict(X_new)

y_pred

y_test[:3]

#Functional API
input=keras.layers.Input(shape=X_train.shape[1:])
hidden1=keras.layers.Dense(30,activation='relu')(input)
hidden2=keras.layers.Dense(30,activation='relu')(hidden1)
concat=keras.layers.Concatenate()([input,hidden2])
output=keras.layers.Dense(1)(concat)
model=keras.models.Model(inputs=[input],outputs=[output])
model.summary()

# Commented out IPython magic to ensure Python compatibility.
#Keras Tuner Library
# %pip install -q -U keras-tuner

import keras_tuner as kt
import tensorflow as tf
from tensorflow import keras
fashion_mnsit=keras.datasets.fashion_mnist
(X_train_full,y_train_full),(X_test,y_test)=fashion_mnsit.load_data()
X_valid,X_train=X_train_full[:5000]/255.0,X_train_full[5000:]/255.0
y_valid,y_train=y_train_full[:5000],y_train_full[5000:]
class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']
class_names[y_train[0]]
X_new=X_test[:3]

def build_model(hp):
  n_hidden=hp.Int('n_hidden',min_value=0,max_value=8,default=2)
  n_neurons=hp.Int('n_neurons',min_value=16,max_value=256)
  learning_rate=hp.Float('learning_rate',min_value=1e-4,max_value=1e-2,sampling='log')
  optimizer=hp.Choice('optimizer',['sgd','adam'])
  if optimizer=='sgd':
    optimizer=keras.optimizers.SGD(learning_rate=learning_rate)
  else:
    optimizer=keras.optimizers.Adam(learning_rate=learning_rate)
  model=tf.keras.Sequential()
  model.add(tf.keras.layers.Flatten())
  for _ in range(n_hidden):
    model.add(keras.layers.Dense(n_neurons,activation='relu'))
  model.add(keras.layers.Dense(10,activation='softmax'))
  model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])
  return model

random_seach_tuner=kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5,overwrite=True,directory='fashion_mnsit',project_name='my_rnd_search',seed=42)
random_seach_tuner.search(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid))
top3models=random_seach_tuner.get_best_models(num_models=3)
best_model=top3models[0]
top3_params=random_seach_tuner.get_best_hyperparameters(num_trials=3)
best_params=top3_params[0]
best_trail=random_seach_tuner.oracle.get_best_trials(num_trials=1)[0]
best_trail.summary()
best_trail.metrics.get_last_value('val_accuracy')
best_model.fit(X_train,y_train,epochs=10)
test_loss,test_acc=best_model.evaluate(X_test,y_test)
print(f'Test accuracy:{test_acc:.3f}')
best_model.summary()

import numpy as np

# Define the unit step function
def unitStep(v):
    if v >= 0:
        return 1
    else:
        return 0

# Define the perceptron model
def perceptronModel(x, w, b):
    v = np.dot(w, x) + b
    output = unitStep(v)
    return output

# Define NOT logic function
def NOT_logicFunction(x):
    wNOT = -1
    bNOT = 0.5
    return perceptronModel(x, wNOT, bNOT)

# Define AND logic function
def AND_logicFunction(x):
    wAND = np.array([0.6, 0.6])
    bAND = -1
    return perceptronModel(x, wAND, bAND)

# Define OR logic function
def OR_logicFunction(x):
    wOR = np.array([1, 1])
    bOR = -0.5
    return perceptronModel(x, wOR, bOR)

# Define XOR logic function using AND, OR, and NOT functions
def XOR_logicFunction(x):
    y1 = AND_logicFunction(x)
    y2 = OR_logicFunction(x)
    y3 = NOT_logicFunction(y1)
    final_x = np.array([y2, y3])
    finalOutput = AND_logicFunction(final_x)
    return finalOutput

# Test cases
test1 = np.array([0, 1])
test2 = np.array([1, 1])
test3 = np.array([0, 0])
test4 = np.array([1, 0])

print("XOR({}, {}) = {}".format(0, 1, XOR_logicFunction(test1)))
print("XOR({}, {}) = {}".format(1, 1, XOR_logicFunction(test2)))
print("XOR({}, {}) = {}".format(0, 0, XOR_logicFunction(test3)))
print("XOR({}, {}) = {}".format(1, 0, XOR_logicFunction(test4)))

import numpy as np

# Define the unit step function
def unitStep(v):
    return 1 if v >= 0 else 0

# Define the perceptron model
def perceptronModel(x, w, b):
    v = np.dot(w, x) + b
    output = unitStep(v)
    return output

# Perceptron update rule
def perceptronUpdate(x, w, b, target, learning_rate=0.1):
    output = perceptronModel(x, w, b)
    error = target - output
    # Update weights and bias
    w += learning_rate * error * x
    b += learning_rate * error
    return w, b

# Logic functions with initial weights and biases for each gate
def AND_logicFunction(x, w, b):
    return perceptronModel(x, w, b)

def OR_logicFunction(x, w, b):
    return perceptronModel(x, w, b)

def NOT_logicFunction(x, w, b):
    return perceptronModel(x, w, b)

# Training data for XOR
XOR_inputs = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])
XOR_outputs = np.array([0, 1, 1, 0])

# Initialize weights and biases for AND, OR, and NOT logic
w_AND = np.random.rand(2)
b_AND = -1.5

w_OR = np.random.rand(2)
b_OR = -0.5

w_NOT = np.array([-1])
b_NOT = 0.5

# Training loop for XOR
epochs = 1000
learning_rate = 0.1

for epoch in range(epochs):
    for x, target in zip(XOR_inputs, XOR_outputs):
        # Calculate intermediate gates
        y1 = AND_logicFunction(x, w_AND, b_AND)
        y2 = OR_logicFunction(x, w_OR, b_OR)
        y3 = NOT_logicFunction(np.array([y1]), w_NOT, b_NOT)

        # Combine AND and NOT outputs to get final XOR output
        final_x = np.array([y2, y3])
        finalOutput = AND_logicFunction(final_x, w_AND, b_AND)

        # Update weights and biases for each gate
        w_AND, b_AND = perceptronUpdate(final_x, w_AND, b_AND, target, learning_rate)
        w_OR, b_OR = perceptronUpdate(x, w_OR, b_OR, target, learning_rate)
        w_NOT, b_NOT = perceptronUpdate(np.array([y1]), w_NOT, b_NOT, 1 - y1, learning_rate) # NOT should flip y1

# Test the model after training
def XOR_logicFunction(x):
    y1 = AND_logicFunction(x, w_AND, b_AND)
    y2 = OR_logicFunction(x, w_OR, b_OR)
    y3 = NOT_logicFunction(np.array([y1]), w_NOT, b_NOT)
    final_x = np.array([y2, y3])
    finalOutput = AND_logicFunction(final_x, w_AND, b_AND)
    return finalOutput

# Print the results
print("XOR(0, 1) =", XOR_logicFunction(np.array([0, 1])))
print("XOR(1, 1) =", XOR_logicFunction(np.array([1, 1])))
print("XOR(0, 0) =", XOR_logicFunction(np.array([0, 0])))
print("XOR(1, 0) =", XOR_logicFunction(np.array([1, 0])))

import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
import numpy as np
import matplotlib.pyplot as plt

# 1. Create synthetic data
def create_data():
    X = np.random.randn(1000, 10)
    y = np.random.randn(1000, 1)
    return X, y

# 2. Define a simple deep neural network
def create_model():
    model = models.Sequential([
        layers.Dense(50, activation='relu', input_shape=(10,)),
        layers.Dense(20, activation='relu'),
        layers.Dense(1)
    ])
    return model

# 3. Train the model and capture loss values, showing the loss per epoch
def train_model_with_history(model, optimizer, X, y, batch_size, epochs, optimizer_name):
    model.compile(optimizer=optimizer, loss='mean_squared_error')
    history = []
    for epoch in range(epochs):
        hist = model.fit(X, y, batch_size=batch_size, epochs=1, verbose=0)
        loss = hist.history['loss'][0]
        history.append(loss)
        print(f"Epoch {epoch+1}/{epochs} - {optimizer_name} loss: {loss:.4f}")
    return history

# 4. Compare performance of SGD and Adam
# Load data
X, y = create_data()

# Create models for SGD and Adam
model_sgd = create_model()
model_adam = create_model()

# Optimizers
optimizer_sgd = optimizers.SGD(learning_rate=0.01)
optimizer_adam = optimizers.Adam(learning_rate=0.001)

# Set training parameters
epochs = 50
batch_size = 32

# Train models and capture loss history, while printing epoch iterations
print("\nTraining with SGD optimizer")
sgd_loss = train_model_with_history(model_sgd, optimizer_sgd, X, y, batch_size, epochs, 'SGD')

print("\nTraining with Adam optimizer")
adam_loss = train_model_with_history(model_adam, optimizer_adam, X, y, batch_size, epochs, 'Adam')

# 5. Plot the loss curves for comparison
plt.plot(range(1, epochs + 1), sgd_loss, label='SGD', color='blue')
plt.plot(range(1, epochs + 1), adam_loss, label='Adam', color='orange')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("SGD vs Adam Optimizer: Loss Comparison")
plt.legend()
plt.grid(True)
plt.show()

#importing necessary modeules
import tensorflow as tf
from tensorflow.keras import layers, models, datasets
import matplotlib.pyplot as plt

#load and preprocess the mnsit dataset
(train_images,train_labels),(test_images,test_labels)=(datasets.mnist.load_data())

#normalize pixel values to be between 0 and 1
train_images=train_images.reshape((train_images.shape[0],28,28,1)).astype('float32')/255
test_images=test_images.reshape((test_images.shape[0],28,28,1)).astype('float32')/255

#define the cnn model
model=models.Sequential()

#add convolutional layers,followed by pooling layers
model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3),activation='relu'))

#add dense layers for classication
model.add(layers.Flatten())
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dense(10,activation='softmax'))

#compile the model
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#train th model
history=model.fit(train_images,train_labels,epochs=5,validation_data=(test_images,test_labels))

#evaluate the model on the test set
test_loss,test_acc=model.evaluate(test_images,test_labels)
print(f"test accuracy:{test_acc}")

#plot training and validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train','Test'],loc='upper left')
plt.show()

#plot training and validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model accuracy')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train','Test'],loc='upper left')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import cifar10  # Assuming you're using CIFAR-10

# Load and preprocess the dataset (CIFAR-10 in this case)
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

# Preprocess the data
train_images = train_images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0

# Reshape the data for LeNet (CIFAR-10 images are 32x32x3)
train_images = np.resize(train_images, (train_images.shape[0], 32, 32, 3))
test_images = np.resize(test_images, (test_images.shape[0], 32, 32, 3))

# One-hot encode the labels
train_labels = to_categorical(train_labels, num_classes=10)
test_labels = to_categorical(test_labels, num_classes=10)

# Split into validation data (80/20 split)
val_images = train_images[40000:]
val_labels = train_labels[40000:]
train_images = train_images[:40000]
train_labels = train_labels[:40000]

# LeNet Model (32x32 images)
def lenet(input_shape, num_classes):
    model = models.Sequential()
    model.add(layers.Conv2D(6, (5, 5), activation='tanh', input_shape=input_shape))
    model.add(layers.AvgPool2D((2, 2)))
    model.add(layers.Conv2D(16, (5, 5), activation='tanh'))
    model.add(layers.AvgPool2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(120, activation='tanh'))
    model.add(layers.Dense(84, activation='tanh'))
    model.add(layers.Dense(num_classes, activation='softmax'))
    return model

# AlexNet Model (224x224 images)
def alexnet(input_shape, num_classes):
    model = models.Sequential()
    model.add(layers.Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D((3, 3), strides=2))
    model.add(layers.Conv2D(256, (5, 5), activation='relu'))
    model.add(layers.MaxPooling2D((3, 3), strides=2))
    model.add(layers.Conv2D(384, (3, 3), activation='relu'))
    model.add(layers.Conv2D(384, (3, 3), activation='relu'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu'))
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(num_classes, activation='softmax'))
    return model

# GoogLeNet Model (InceptionV3)
def googlenet(input_shape, num_classes):
    model = InceptionV3(weights=None, input_shape=input_shape, classes=num_classes)
    return model

# Create and compile the models
lenet_model = lenet(input_shape=(32, 32, 3), num_classes=10)
alexnet_model = alexnet(input_shape=(224, 224, 3), num_classes=10)
googlenet_model = googlenet(input_shape=(224, 224, 3), num_classes=10)

# Compile the models
lenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
googlenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the models (Note: AlexNet and GoogLeNet require 224x224 images)
history_lenet = lenet_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels), batch_size=32)
history_alexnet = alexnet_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels), batch_size=32)
history_googlenet = googlenet_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels), batch_size=32)

# Evaluate the models
test_loss_lenet, test_accuracy_lenet = lenet_model.evaluate(test_images, test_labels)
test_loss_alexnet, test_accuracy_alexnet = alexnet_model.evaluate(test_images, test_labels)
test_loss_googlenet, test_accuracy_googlenet = googlenet_model.evaluate(test_images, test_labels)

print(f'LeNet Test Accuracy: {test_accuracy_lenet}')
print(f'AlexNet Test Accuracy: {test_accuracy_alexnet}')
print(f'GoogLeNet Test Accuracy: {test_accuracy_googlenet}')

# Plot the accuracy comparison
plt.plot(history_lenet.history['accuracy'], label='LeNet')
plt.plot(history_alexnet.history['accuracy'], label='AlexNet')
plt.plot(history_googlenet.history['accuracy'], label='GoogLeNet')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Model Accuracy Comparison')
plt.show()

import tensorflow as tf
from tensorflow.keras import layers, models, datasets

# Load and preprocess the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# Normalize pixel values to be between 0 and 1
train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255

# Define the model
model = models.Sequential([
    layers.Conv2D(64, kernel_size=7, activation='relu', padding="SAME", input_shape=[28, 28, 1]),
    layers.MaxPooling2D(pool_size=2),

    layers.Conv2D(128, kernel_size=3, activation='relu', padding="SAME"),
    layers.Conv2D(128, kernel_size=3, activation='relu', padding="SAME"),
    layers.MaxPooling2D(pool_size=2),

    layers.Conv2D(256, kernel_size=3, activation='relu', padding="SAME"),
    layers.Conv2D(256, kernel_size=3, activation='relu', padding="SAME"),
    layers.MaxPooling2D(pool_size=2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),

    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),

    layers.Dense(32, activation='relu'),
    layers.Dropout(0.5),

    layers.Dense(10, activation='softmax')  # 10 classes for MNIST digits (0-9)
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test accuracy: {test_acc}")

from functools import partial
from tensorflow import keras
DefaultConv2D= partial(keras.layers.Conv2D,kernel_size=3,strides=1,padding="SAME",use_bias=False)
class ResidualUnit(keras.layers.Layer):
    def __init__(self,filters,strides=1,activation="relu",**kwargs):
        super().__init__(**kwargs)
        self.activation=keras.activations.get(activation)
        self.main_layers=[
            DefaultConv2D(filters,strides=strides),
            keras.layers.BatchNormalization(),
            self.activation,
            DefaultConv2D(filters),
            keras.layers.BatchNormalization()
        ]
        self.skip_layers=[]
        if strides>1:
            self.skip_layers=[
                DefaultConv2D(filters,kernel_size=1,strides=strides),
                keras.layers.BatchNormalization()
            ]
    def call(self,inputs):
        z=inputs
        for layer in self.main_layers:
            z=layer(z)
        skip_z=inputs
        for layer in self.skip_layers:
            skip_z=layer(skip_z)
        return self.activation(z+skip_z)
model=keras.models.Sequential()
model.add(DefaultConv2D(64,kernel_size=7,strides=2,input_shape=[28,28,1]))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Activation("relu"))
model.add(keras.layers.MaxPool2D(pool_size=3,strides=2,padding="same"))
prev_filters=64
for filters in [64]*3+[128]*4+[256]*6+[512]*3:
    strides=1 if filters==prev_filters else 2
    model.add(ResidualUnit(filters,strides=strides))
    prev_filters=filters
model.add(keras.layers.GlobalAvgPool2D())
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(10,activation="softmax"))

import tensorflow as tf
from tensorflow.keras import layers, models, datasets

# Load and preprocess the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# Normalize pixel values to be between 0 and 1
train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test accuracy: {test_acc}")

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing import image
from tensorflow.keras.utils import to_categorical

# Load the CIFAR-10 dataset (32x32 images in 10 classes)
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Preprocess the data: normalize to [0, 1] and convert labels to one-hot encoding
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Resize images to 224x224 for ResNet50
x_train_resized = tf.image.resize(x_train, (224, 224))
x_test_resized = tf.image.resize(x_test, (224, 224))

# Load the ResNet50 model with pre-trained ImageNet weights, excluding the top (classification) layer
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of the base model
base_model.trainable = False

# Add custom layers on top for CIFAR-10 classification
model = models.Sequential([
    base_model,  # Add ResNet50 as the base
    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce dimensions
    layers.Dense(1024, activation='relu'),  # Fully connected layer
    layers.Dropout(0.5),  # Dropout for regularization
    layers.Dense(10, activation='softmax')  # Output layer with 10 classes for CIFAR-10
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train_resized, y_train, epochs=10, batch_size=64, validation_data=(x_test_resized, y_test))

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(x_test_resized, y_test)
print(f"Test accuracy: {test_acc:.4f}")

